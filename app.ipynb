{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Markdown, HTML, display\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Azure OpenAI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    openai_api_veriosn = \"2023-05-15\"\n",
    "    azure_deployment=\"gpt-4-1106\"\n",
    "    azure_endpoint=os.getenv(\"https://testadri.openai.azure.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leveraging LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    openai_api_version = CFG.openai_api_veriosn, \n",
    "    azure_deployment = CFG.azure_deployment, \n",
    "    azure_endpoint = CFG.azure_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=\"Translate this sentence from English \"\n",
    "    \"to French and Spanish. I like red cars and \"\n",
    "    \"blue houses, but my dog is yellow.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engaging the model to get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2: Interacting with a CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/all-states-history.csv\").fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Langchain dataframe agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(llm=model,df=df,verbose=True)\n",
    "\n",
    "agent.invoke(\"how many rows are there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design your prompt and ask your question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PROMPT_PREFIX = \"\"\"\n",
    "First set the pandas display options to show all the columns,\n",
    "get the column names, then answer the question.\n",
    "\"\"\"\n",
    "\n",
    "CSV_PROMPT_SUFFIX = \"\"\"\n",
    "- **ALWAYS** before giving the Final Answer, try another method.\n",
    "Then reflect on the answers of the two methods you did and ask yourself\n",
    "if it answers correctly the original question.\n",
    "If you are not sure, try another method.\n",
    "- If the methods tried do not give the same result,reflect and\n",
    "try again until you have two methods that have the same result.\n",
    "- If you still cannot arrive to a consistent result, say that\n",
    "you are not sure of the answer.\n",
    "- If you are sure of the correct answer, create a beautiful\n",
    "and thorough response using Markdown.\n",
    "- **DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE,\n",
    "ONLY USE THE RESULTS OF THE CALCULATIONS YOU HAVE DONE**.\n",
    "- **ALWAYS**, as part of your \"Final Answer\", explain how you got\n",
    "to the answer on a section that starts with: \"\\n\\nExplanation:\\n\".\n",
    "In the explanation, mention the column names that you used to get\n",
    "to the final answer.\n",
    "\"\"\"\n",
    "\n",
    "QUESTION = \"How may patients were hospitalized during July 2020\" \n",
    "\"in Texas, and nationwide as the total of all states?\"\n",
    "\"Use the hospitalizedIncrease column\" \n",
    "\n",
    "\n",
    "agent.invoke(CSV_PROMPT_PREFIX + QUESTION + CSV_PROMPT_SUFFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3: Connecting to a SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recover the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/all-states-history.csv\").fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move the data to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your SQLite database file\n",
    "database_file_path = \"./db/test.db\"\n",
    "\n",
    "# Create an engine to connect to the SQLite database\n",
    "# SQLite only requires the path to the database file\n",
    "engine = create_engine(f'sqlite:///{database_file_path}')\n",
    "file_url = \"./data/all-states-history.csv\"\n",
    "df = pd.read_csv(file_url).fillna(value = 0)\n",
    "df.to_sql(\n",
    "    'all_states_history',\n",
    "    con=engine,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the SQL prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_AGENT_PREFIX = \"\"\"\n",
    "\n",
    "You are an agent designed to interact with a SQL database.\n",
    "## Instructions:\n",
    "- Given an input question, create a syntactically correct {dialect} query\n",
    "to run, then look at the results of the query and return the answer.\n",
    "- Unless the user specifies a specific number of examples they wish to\n",
    "obtain, **ALWAYS** limit your query to at most {top_k} results.\n",
    "- You can order the results by a relevant column to return the most\n",
    "interesting examples in the database.\n",
    "- Never query for all the columns from a specific table, only ask for\n",
    "the relevant columns given the question.\n",
    "- You have access to tools for interacting with the database.\n",
    "- You MUST double check your query before executing it.If you get an error\n",
    "while executing a query,rewrite the query and try again.\n",
    "- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.)\n",
    "to the database.\n",
    "- DO NOT MAKE UP AN ANSWER OR USE PRIOR KNOWLEDGE, ONLY USE THE RESULTS\n",
    "OF THE CALCULATIONS YOU HAVE DONE.\n",
    "- Your response should be in Markdown. However, **when running  a SQL Query\n",
    "in \"Action Input\", do not include the markdown backticks**.\n",
    "Those are only for formatting the response, not for executing the command.\n",
    "- ALWAYS, as part of your final answer, explain how you got to the answer\n",
    "on a section that starts with: \"Explanation:\". Include the SQL query as\n",
    "part of the explanation section.\n",
    "- If the question does not seem related to the database, just return\n",
    "\"I don\\'t know\" as the answer.\n",
    "- Only use the below tools. Only use the information returned by the\n",
    "below tools to construct your query and final answer.\n",
    "- Do not make up table names, only use the tables returned by any of the\n",
    "tools below.\n",
    "\n",
    "## Tools:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSSQL_AGENT_FORMAT_INSTRUCTIONS = \"\"\"\n",
    "\n",
    "## Use the following format:\n",
    "\n",
    "Question: the input question you must answer.\n",
    "Thought: you should always think about what to do.\n",
    "Action: the action to take, should be one of [{tool_names}].\n",
    "Action Input: the input to the action.\n",
    "Observation: the result of the action.\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: the final answer to the original input question.\n",
    "\n",
    "Example of Final Answer:\n",
    "<=== Beginning of example\n",
    "\n",
    "Action: query_sql_db\n",
    "Action Input: \n",
    "SELECT TOP (10) [death]\n",
    "FROM covidtracking \n",
    "WHERE state = 'TX' AND date LIKE '2020%'\n",
    "\n",
    "Observation:\n",
    "[(27437.0,), (27088.0,), (26762.0,), (26521.0,), (26472.0,), (26421.0,), (26408.0,)]\n",
    "Thought:I now know the final answer\n",
    "Final Answer: There were 27437 people who died of covid in Texas in 2020.\n",
    "\n",
    "Explanation:\n",
    "I queried the `covidtracking` table for the `death` column where the state\n",
    "is 'TX' and the date starts with '2020'. The query returned a list of tuples\n",
    "with the number of deaths for each day in 2020. To answer the question,\n",
    "I took the sum of all the deaths in the list, which is 27437.\n",
    "I used the following query\n",
    "\n",
    "```sql\n",
    "SELECT [death] FROM covidtracking WHERE state = 'TX' AND date LIKE '2020%'\"\n",
    "```\n",
    "===> End of Example\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the Azure Chat model and create the SQL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_deployment=\"gpt-4-1106\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    temperature=0, \n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(f'sqlite:///{database_file_path}')\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"\"\"How may patients were hospitalized during October 2020\n",
    "in New York, and nationwide as the total of all states?\n",
    "Use the hospitalizedIncrease column\n",
    "\"\"\"\n",
    "\n",
    "agent_executor_SQL = create_sql_agent(\n",
    "    prefix=MSSQL_AGENT_PREFIX,\n",
    "    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    top_k=30,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke the SQL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_SQL.invoke(QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4: Azure OpenAI Function Calling Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using an illustrative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location. \n",
    "    The default unit when not specified is fahrenheit\"\"\"\n",
    "    if \"new york\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"New York\", \"temperature\": \"40\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"50\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"las vegas\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"Las Vegas\", \"temperature\": \"70\", \"unit\": unit}\n",
    "        )\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"location\": location, \"temperature\": \"unknown\"}\n",
    "        )\n",
    "\n",
    "get_current_weather(\"New York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"What's the weather like in San Francisco,\n",
    "                   New York, and Las Vegass?\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"\"\"Get the current weather in a given\n",
    "                              location.The default unit when not\n",
    "                              specified is fahrenheit\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The city and state,\n",
    "                                        e.g. San Francisco, CA\"\"\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"default\":\"fahrenheit\",\n",
    "                        \"enum\": [ \"fahrenheit\", \"celsius\"],\n",
    "                        \"description\": \"\"\"The messuring unit for\n",
    "                                          the temperature.\n",
    "                                          If not explicitly specified\n",
    "                                          the default unit is \n",
    "                                          fahrenheit\"\"\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.chat.completions.create(\n",
    "    model=\"gpt-4-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\", \n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    print (tool_calls)\n",
    "    \n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "    }\n",
    "     \n",
    "    messages.append(response_message)  \n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  \n",
    "    print (messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = model.chat.completions.create(\n",
    "            model=\"gpt-4-1106\",\n",
    "            messages=messages,\n",
    "        )\n",
    "print (second_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using our SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/all-states-history.csv\").fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file_path = \"./db/test.db\"\n",
    "\n",
    "engine = create_engine(f'sqlite:///{database_file_path}')\n",
    "\n",
    "df.to_sql(\n",
    "    'all_states_history',\n",
    "    con=engine,\n",
    "    if_exists='replace',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sqlalchemy import text\n",
    "\n",
    "def get_hospitalized_increase_for_state_on_date(state_abbr, specific_date):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT date, hospitalizedIncrease\n",
    "        FROM all_states_history\n",
    "        WHERE state = '{state_abbr}' AND date = '{specific_date}';\n",
    "        \"\"\"\n",
    "        query = text(query)\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            result = pd.read_sql_query(query, connection)\n",
    "        if not result.empty:\n",
    "            return result.to_dict('records')[0]\n",
    "        else:\n",
    "            return np.nan\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_cases_for_state_on_date(state_abbr, specific_date):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT date, state, positiveIncrease AS positive_cases\n",
    "        FROM all_states_history\n",
    "        WHERE state = '{state_abbr}' AND date = '{specific_date}';\n",
    "        \"\"\"\n",
    "        query = text(query)\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            result = pd.read_sql_query(query, connection)\n",
    "        if not result.empty:\n",
    "            return result.to_dict('records')[0]\n",
    "        else:\n",
    "            return np.nan\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hospitalized_increase_for_state_on_date(\"AK\",\"2021-03-05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the function calling against the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\" how many hospitalized people we had in Alaska\n",
    "                    the 2021-03-05?\"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_sql = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_hospitalized_increase_for_state_on_date\",\n",
    "            \"description\": \"\"\"Retrieves the daily increase in\n",
    "                              hospitalizations for a specific state\n",
    "                              on a specific date.\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"state_abbr\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The abbreviation of the state\n",
    "                                          (e.g., 'NY', 'CA').\"\"\"\n",
    "                    },\n",
    "                    \"specific_date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The specific date for\n",
    "                                          the query in 'YYYY-MM-DD'\n",
    "                                          format.\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"state_abbr\", \"specific_date\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_positive_cases_for_state_on_date\",\n",
    "            \"description\": \"\"\"Retrieves the daily increase in \n",
    "                              positive cases for a specific state\n",
    "                              on a specific date.\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"state_abbr\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The abbreviation of the \n",
    "                                          state (e.g., 'NY', 'CA').\"\"\"\n",
    "                    },\n",
    "                    \"specific_date\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"\"\"The specific date for the\n",
    "                                          query in 'YYYY-MM-DD'\n",
    "                                          format.\"\"\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"state_abbr\", \"specific_date\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.chat.completions.create(\n",
    "    model=\"gpt-4-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools_sql,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "if tool_calls:\n",
    "    print (tool_calls)\n",
    "    \n",
    "    available_functions = {\n",
    "        \"get_positive_cases_for_state_on_date\": get_positive_cases_for_state_on_date,\n",
    "        \"get_hospitalized_increase_for_state_on_date\":get_hospitalized_increase_for_state_on_date\n",
    "    }  \n",
    "    messages.append(response_message)  \n",
    "   \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        function_response = function_to_call(\n",
    "            state_abbr=function_args.get(\"state_abbr\"),\n",
    "            specific_date=function_args.get(\"specific_date\"),\n",
    "        )\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(function_response),\n",
    "            }\n",
    "        ) \n",
    "    print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = model.chat.completions.create(\n",
    "            model=\"gpt-4-1106\",\n",
    "            messages=messages,\n",
    "        )\n",
    "print (second_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 5: Leveraging Assistants API for SQL Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/all-states-history.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_positive_cases_for_state_on_date\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_hospitalized_increase_for_state_on_date\n",
      "File \u001b[0;32m~/Downloads/database-agent/helper.py:10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mos.makedirs(\"data\",exist_ok=True)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m!wget https://covidtracking.com/data/download/all-states-history.csv -P ./data/\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mfile_url = \"./data/all-states-history.csv\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/all-states-history.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m database_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./db/test.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatabase_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/all-states-history.csv'"
     ]
    }
   ],
   "source": [
    "from helper import get_positive_cases_for_state_on_date\n",
    "from helper import get_hospitalized_increase_for_state_on_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
